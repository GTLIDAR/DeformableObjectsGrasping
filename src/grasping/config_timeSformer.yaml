# Transformer architecture specification

use_gpu: 1 
num_workers: 4
batch_size: 2
lr: 5e-5

#Training Data Dir
Train_data_dir: ../../data/fruit_data


#Data processing parameters
Fruit_type: ['apple', 'lemon', 'orange', 'plum', 'tomato']
label_encoding : {'apple':'0', 'lemon':'1', 'orange':'2', 'plum':'3', 'tomato':'4'}
Tactile_Image_width: 200  # Raw Image width (for slip detection dataset)
Tactile_Image_height: 150 # Raw Image Height (for slip detection dataset)
Tactile_scale_ratio: 1
Visual_Image_width: 640
Visual_Image_height: 480
Visual_scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
#scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
video_length: 8

# Model options: vivit_fdp_two_fruit, timeSformer_orig_two_fruit, basic_CNN
Model_name: timeSformer_orig_two
Modality: Combined # Three options, Combined, Tactile, Visual
base_network: vgg_19 # only used for the basic_CNN architecture, there are some other options
# vgg_19; inception_v3; alexnet(debug)


#Training Parameters
attn_drop: 0.2  # timeSformer_orig_two
mlp_drop: 0.2 # timeSformer_orig_two
CNN_drop: 0.2 # used for basic_CNN
LSTM_drop: 0.2 # used for basic_CNN
pretrained: True # used for basic_CNN, load pretrained model or not.
frozen_weights: False # used for basic_CNN, CNN parameters are trainable or not
epochs: 20
print_interval: 1
save_dir: ./Trained_Model
use_random_seed: 0  #Set to 1 to use random seed. Otherwise, seed below is used for reproducibility
seed: 42 #Only used if use_random_seed = 1
skip_init_in_train: 1
test_eval: 1
pretrained: 1
pretrained_path: Pretrained/vivit_fdp_two.pt
